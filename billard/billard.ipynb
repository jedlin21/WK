{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projekt zaliczeniowy - Opis obrazu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Skład zespołu:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Julia May 150653\n",
    "- Patryk Jedlikowski 136723\n",
    "- Mikołaj Sienkiewicz 136309"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "import PIL\n",
    "import os\n",
    "import sys\n",
    "import glob\n",
    "import random\n",
    "from pprint import pprint\n",
    "from ipywidgets import Video\n",
    "from PIL import Image\n",
    "from PIL.ExifTags import TAGS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zbiór danych"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Przygotowany zbiór danych prezentujących fragmenty rozgrywek bilardowych znajduje się w repozytorium GitHub: https://github.com/jedlin21/WK/tree/master/billard/data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Przydatne funkcje"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow(a):\n",
    "  a = a.clip(0, 255).astype('uint8')\n",
    "  if a.ndim == 3:\n",
    "    if a.shape[2] == 4:\n",
    "      a = cv2.cvtColor(a, cv2.COLOR_BGRA2RGBA)\n",
    "    else:\n",
    "      a = cv2.cvtColor(a, cv2.COLOR_BGR2RGB)\n",
    "  display(PIL.Image.fromarray(a))\n",
    "\n",
    "def create_tracker(tracker_type):\n",
    "  tracker_types = ['BOOSTING', 'MIL','KCF', 'TLD', 'MEDIANFLOW', 'GOTURN', 'MOSSE', 'CSRT']\n",
    "\n",
    "  if tracker_type == 'BOOSTING':\n",
    "      return cv2.TrackerBoosting_create()\n",
    "  if tracker_type == 'MIL':\n",
    "      return cv2.TrackerMIL_create()\n",
    "  if tracker_type == 'KCF':\n",
    "      return cv2.TrackerKCF_create()\n",
    "  if tracker_type == 'TLD':\n",
    "      return cv2.TrackerTLD_create()\n",
    "  if tracker_type == 'MEDIANFLOW':\n",
    "      return cv2.TrackerMedianFlow_create()\n",
    "  if tracker_type == 'GOTURN':\n",
    "      return cv2.TrackerGOTURN_create()\n",
    "  if tracker_type == 'MOSSE':\n",
    "      return cv2.TrackerMOSSE_create()\n",
    "  if tracker_type == \"CSRT\":\n",
    "      return cv2.TrackerCSRT_create()\n",
    "\n",
    "def draw_bbox(frame, bbox, color=(255, 255, 255)):\n",
    "  p1 = (int(bbox[0]), int(bbox[1]))\n",
    "  p2 = (int(bbox[0] + bbox[2]), int(bbox[1] + bbox[3]))\n",
    "  cv2.rectangle(frame, p1, p2, color, 2, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Przykładowe filmy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_path_11 = './data/11.mp4'\n",
    "video_path_22 = './data/22.mp4'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_example_clip(video_path):\n",
    "    free_kick = cv2.VideoCapture(video_path)\n",
    "    if free_kick.isOpened():\n",
    "        print('Film wczytany!')\n",
    "\n",
    "    free_kick_width = int(free_kick.get(3))\n",
    "    free_kick_height = int(free_kick.get(4))\n",
    "\n",
    "    print(free_kick_height, free_kick_width)\n",
    "\n",
    "    free_kick_fps = free_kick.get(cv2.CAP_PROP_FPS)\n",
    "    print(free_kick_fps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Film wczytany!\n",
      "1080 1920\n",
      "30.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5b951969dda42f08703b8d4687f7d9e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Video(value=b'\\x00\\x00\\x00\\x18ftypmp42\\x00\\x00\\x00\\x00mp41isom\\x00\\x00\\x00(uuid\\\\\\xa7\\x08\\xfb2\\x8eB\\x05\\xa8ae\\…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_example_clip(video_path_11)\n",
    "Video.from_file(video_path_11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Film wczytany!\n",
      "1080 1920\n",
      "30.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9ea4982b9d34096ba2d58814a88ad5a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Video(value=b'\\x00\\x00\\x00\\x18ftypmp42\\x00\\x00\\x00\\x00mp41isom\\x00\\x00\\x00(uuid\\\\\\xa7\\x08\\xfb2\\x8eB\\x05\\xa8ae\\…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_example_clip(video_path_22)\n",
    "Video.from_file(video_path_22)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wykorzystane metody"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "W celu śledzenia ruchu bil na filmie wykorzystaliśmy dwa różne podejścia, jedno oparte na trackerze CSRT, a drugie na Optical Flow. W pierwszym z nich zaimplementowaliśmy również wykrywanie wpadnięcia bili do łuzy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podejście oparte na trackerze CSRT:\n",
    "\n",
    "1. W celu wykrycia początkowego ułożenia bil na stole najpierw dokonujemy transformacji do przestrzeni barw Grayscale, a następnie stosujemy trasformatę Hougha w celu wykrycia okręgów. Nakładamy również ograniczenia na współrzędne X oraz Y, filtrując uzyskane wyniki, aby mieć pewność, że wykryte okręgi znajdują się w obrębie stołu bilardowego.\n",
    "2. Tworzymy osobny tracker CSRT dla każdej wykrytej bili.\n",
    "3. Definiujemy parametry określające szerkość i wysokość łuz oraz współrzędne lewych górnych narożników dla wszystkich łuz.\n",
    "4. Wczytując kolejne klatki filmu iterujemy po wszystkich trackerach i uaktualniamy je a następnie sprawdzamy dla każdego trackera i każdej bili oraz każdego trackera i każdej łuzy czy bila nie znalazła się od nich w odległości mniejszej niż hiperparamter diameter, co oznacza zderzenie bil lub wpadnięcie bili do łuzy, odpowiednio. Jeśli zdarzenie takie nastąpiło zapisujemy na filmie odpowiedni bounding box (w przypadku zderzenia bil biały kwadrat w lewym górnym rogu ekranu zmienia kolor na czarny w momencie zderzenia, a w przypadku wpadnięcia bili do łuzy w miejscu danej łuzy pojawia się czarny kwadrat zaraz po wystąpieniu zdarzenia)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Śledzenie ruchu bil i wpadnięć do łuz z wykorzystaniem trackera CSRT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Przykładowe wyniki przetwarzania z wykorzystaniem tej metody znajdują się w repozytorium GitHub: https://github.com/jedlin21/WK/tree/master/billard/processed (filmy movie11 i movie22)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "clips_to_process = [11, 22]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Film wczytany!\n",
      "1080 1920\n",
      "30.0\n",
      "Film wczytany!\n",
      "1080 1920\n",
      "30.0\n"
     ]
    }
   ],
   "source": [
    "for s in clips_to_process:\n",
    "    \n",
    "    video_path = f'./data/{s}.mp4' \n",
    "    write_path = f'./processed/movie{s}.avi'\n",
    "\n",
    "    free_kick = cv2.VideoCapture(video_path)\n",
    "    if free_kick.isOpened():\n",
    "        print('Film wczytany!')\n",
    "\n",
    "    free_kick_width = int(free_kick.get(3))\n",
    "    free_kick_height = int(free_kick.get(4))\n",
    "\n",
    "    print(free_kick_height, free_kick_width)\n",
    "\n",
    "    free_kick_fps = free_kick.get(cv2.CAP_PROP_FPS)\n",
    "    print(free_kick_fps)\n",
    "\n",
    "    free_kick.set(cv2.CAP_PROP_POS_FRAMES, 0)\n",
    "    ret, frame = free_kick.read()\n",
    "\n",
    "    # bounding boxes dla początkowych pozycji kul bilardowych\n",
    "    old_gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    circles = cv2.HoughCircles(old_gray,cv2.HOUGH_GRADIENT,1,18,param1=80,param2=10,minRadius=10,maxRadius=20)\n",
    "    circles = np.uint16(np.around(circles))\n",
    "    x = circles[circles[...,0]>170]\n",
    "    x = x[x[...,0]<1760]\n",
    "    x = x[x[...,1]>135]\n",
    "    x = x[x[...,1]<920]\n",
    "    circles = x.reshape(1, x.shape[0], 3)\n",
    "\n",
    "    balls = []\n",
    "    for circle in circles[0, :]:\n",
    "        balls.append((circle[0]-circle[2]-10, circle[1]-circle[2]-10, 2*circle[2]+20, 2*circle[2]+20))\n",
    "\n",
    "    balls_tracker = []\n",
    "    for ball_box in balls:\n",
    "        balls_tracker.append(create_tracker('CSRT'))\n",
    "        balls_tracker[-1].init(frame, ball_box)\n",
    "\n",
    "    free_kick_track = cv2.VideoWriter(write_path, cv2.VideoWriter_fourcc(*'DIVX'), free_kick_fps, (free_kick_width, free_kick_height))\n",
    "\n",
    "    free_kick.set(cv2.CAP_PROP_POS_FRAMES, 0)\n",
    "    \n",
    "    while free_kick.isOpened():\n",
    "        \n",
    "        ret, frame = free_kick.read()\n",
    "\n",
    "        if ret:\n",
    "            \n",
    "            frame[...,0] = cv2.GaussianBlur(frame[...,0],(3,3),0)\n",
    "            frame[...,1] = cv2.GaussianBlur(frame[...,1],(3,3),0)\n",
    "            frame[...,2] = cv2.GaussianBlur(frame[...,2],(3,3),0)\n",
    "\n",
    "            frame[0:100,0:100,:]=255\n",
    "            \n",
    "            # hiperparametr definiujący jak daleko od siebie muszą znajdować się składowe X i Y lewych górnych \n",
    "            # narożników bil, które są sprawdzane pod kątem kolizji\n",
    "            diameter=25\n",
    "            \n",
    "            # szerkość i wysokość łuz\n",
    "            pocket_size=50\n",
    "            \n",
    "            # współrzędne lewych górnych narożników łuz\n",
    "            pockets=[(90,140),(90,950),(90,1750),(900,140),(900,950),(900,1750)]\n",
    "\n",
    "            for x,tracker in enumerate(balls_tracker):\n",
    "                \n",
    "                ok, bbox = tracker.update(frame)\n",
    "                MovingX=bbox[0]\n",
    "                MovingY=bbox[1]\n",
    "                \n",
    "                # sprawdzenie czy nastąpiła kolizja\n",
    "                for i,second in enumerate(balls):\n",
    "                    \n",
    "                    StoppedX=second[0]\n",
    "                    StoppedY=second[1]\n",
    "                    \n",
    "                    if i!=x:\n",
    "                        \n",
    "                        if (MovingX-diameter<StoppedX and MovingY-diameter<StoppedY and MovingX>StoppedX and MovingY>StoppedY) \\\n",
    "                        or (MovingX-diameter<StoppedX and MovingY+diameter>StoppedY and MovingX>StoppedX and MovingY<StoppedY) \\\n",
    "                        or (MovingX+diameter>StoppedX and MovingY+diameter>StoppedY and MovingX<StoppedX and MovingY<StoppedY) \\\n",
    "                        or (MovingX+diameter>StoppedX and MovingY-diameter<StoppedY and MovingX<StoppedX and MovingY>StoppedY):\n",
    "                            frame[0:100,0:100,:]=0\n",
    "                            \n",
    "                # sprawdzenie czy bila wpadła do łuzy\n",
    "                for i,second in enumerate(pockets):\n",
    "                    \n",
    "                    StoppedX=second[1]\n",
    "                    StoppedY=second[0]\n",
    "                    \n",
    "                    if i!=x:\n",
    "                        \n",
    "                        if (MovingX-diameter<StoppedX and MovingY-diameter<StoppedY and MovingX>StoppedX and MovingY>StoppedY) \\\n",
    "                        or (MovingX-diameter<StoppedX and MovingY+diameter>StoppedY and MovingX>StoppedX and MovingY<StoppedY) \\\n",
    "                        or (MovingX+diameter>StoppedX and MovingY+diameter>StoppedY and MovingX<StoppedX and MovingY<StoppedY) \\\n",
    "                        or (MovingX+diameter>StoppedX and MovingY-diameter<StoppedY and MovingX<StoppedX and MovingY>StoppedY):\n",
    "                            frame[second[0]:second[0]+pocket_size,second[1]:second[1]+pocket_size,:]=0\n",
    "\n",
    "                if ok: draw_bbox(frame, bbox, (0, 255, 0))\n",
    "\n",
    "            free_kick_track.write(frame)\n",
    "            \n",
    "        else:\n",
    "            break\n",
    "\n",
    "    free_kick_track.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'ffmpeg' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "# konwersja przetworzonych klipów do formatu .mp4\n",
    "for i in clips_to_process:\n",
    "    !ffmpeg -hide_banner -loglevel error -i \"./processed/movie{i}.avi\" -y \"./processed/movie{i}.mp4\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "503fc108134b4e8282e056ef93666aff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Video(value=b'\\x00\\x00\\x00 ftypisom\\x00\\x00\\x02\\x00isomiso2avc1mp41\\x00\\x00\\r\\x1dmoov\\x00\\x00\\x00lmvhd\\x00\\x00…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Video.from_file(f'./processed/movie11.mp4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b72d2ebe5afc4f1aa2661dcdae37eeb5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Video(value=b'\\x00\\x00\\x00 ftypisom\\x00\\x00\\x02\\x00isomiso2avc1mp41\\x00\\x00\\rUmoov\\x00\\x00\\x00lmvhd\\x00\\x00\\x0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Video.from_file(f'./processed/movie22.mp4')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Śledzenie ruchu bil z wykorzystaniem Optical Flow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podejście oparte na Optical Flow:\n",
    "\n",
    "1. W celu wykrycia początkowego ułożenia bil na stole wykonujemy podobne kroki jak w podejściu wykorzystującym tracker CSRT, korzystając z transformaty Hougha, służącej do wykrywania okręgów.\n",
    "2. Wczytując kolejne klatki filmu wywołujemy dla każdej z nich funkcję z OpenCV obliczającą Optical Flow pomiędzy poprzednią i aktualną klatką filmu, która zwraca nowe pozycje śledzonych bil. \n",
    "3. Oznaczamy na filmie aktualne pozycje bil oraz trajektorie, które przebyły."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Przykładowy wynik przetwarzania z wykorzystaniem tej metody znajduje się w repozytorium GitHub: https://github.com/jedlin21/WK/tree/master/billard/processed (film movie_optical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_path = './data/11.mp4' \n",
    "write_path = './processed/movie_optical.avi'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Film wczytany!\n",
      "1080 1920\n",
      "30.0\n"
     ]
    }
   ],
   "source": [
    "traffic = cv2.VideoCapture(video_path)\n",
    "if traffic.isOpened():\n",
    "    print('Film wczytany!')\n",
    "\n",
    "traffic_width = int(traffic.get(3))\n",
    "traffic_height = int(traffic.get(4))\n",
    "\n",
    "print(traffic_height, traffic_width)\n",
    "\n",
    "traffic_fps = traffic.get(cv2.CAP_PROP_FPS)\n",
    "print(traffic_fps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "240a5b2c8bb846399751d5209b20771a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Video(value=b'\\x00\\x00\\x00\\x18ftypmp42\\x00\\x00\\x00\\x00mp41isom\\x00\\x00\\x00(uuid\\\\\\xa7\\x08\\xfb2\\x8eB\\x05\\xa8ae\\…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Video.from_file(video_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_params = dict(\n",
    "                      maxCorners=100,\n",
    "                      qualityLevel=0.3,\n",
    "                      minDistance=7,\n",
    "                      blockSize=7\n",
    "                     )\n",
    "\n",
    "lk_params = dict(\n",
    "                 winSize=(15,15),\n",
    "                 maxLevel=2,\n",
    "                 criteria=(cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 10, 0.03)\n",
    "                )\n",
    "\n",
    "color = np.random.randint(0,255,(100,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# startowe pozycje bil na filmie\n",
    "traffic.set(cv2.CAP_PROP_POS_FRAMES, 0)\n",
    "ret, old_frame = traffic.read()\n",
    "\n",
    "old_gray = cv2.cvtColor(old_frame, cv2.COLOR_BGR2GRAY)\n",
    "circles = cv2.HoughCircles(old_gray,cv2.HOUGH_GRADIENT,1,18,param1=80,param2=10,minRadius=10,maxRadius=20)\n",
    "circles = np.uint16(np.around(circles))\n",
    "x = circles[circles[...,0]>170]\n",
    "x = x[x[...,0]<1760]\n",
    "x = x[x[...,1]>135]\n",
    "x = x[x[...,1]<920]\n",
    "circles = x.reshape(1, x.shape[0], 3)\n",
    "p0 = circles[...,:2].reshape(circles.shape[1],1,2).astype('float')\n",
    "p0 = p0.astype('float32')\n",
    "mask = np.zeros_like(old_frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# śledzenie ruchu bil\n",
    "traffic_optical_flow = cv2.VideoWriter(write_path, cv2.VideoWriter_fourcc(*'DIVX'), traffic_fps, (traffic_width, traffic_height))\n",
    "traffic.set(cv2.CAP_PROP_POS_FRAMES, 0)\n",
    "\n",
    "while traffic.isOpened():\n",
    "    \n",
    "    ret, frame = traffic.read()\n",
    "    \n",
    "    if ret:\n",
    "        frame_gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        frame_gray = cv2.GaussianBlur(frame_gray,(3,3),0)\n",
    "        p1, st, err = cv2.calcOpticalFlowPyrLK(old_gray, frame_gray, p0, None, **lk_params)\n",
    "        \n",
    "        if p1 is not None:\n",
    "            good_new = p1[st==1]\n",
    "            good_old = p0[st==1]\n",
    "\n",
    "        for i,(new,old) in enumerate(zip(good_new, good_old)):\n",
    "            a,b = new.ravel()\n",
    "            c,d = old.ravel()\n",
    "            mask = cv2.line(mask, (int(a),int(b)),(int(c),int(d)), color[i].tolist(), 2)\n",
    "            frame = cv2.circle(frame,(int(a),int(b)),5,color[i].tolist(),-1)\n",
    "\n",
    "        old_gray = frame_gray.copy()\n",
    "        p0 = good_new.reshape(-1,1,2)\n",
    "\n",
    "        traffic_optical_flow.write(cv2.add(frame, mask))\n",
    "        \n",
    "    else:\n",
    "        break\n",
    "\n",
    "traffic_optical_flow.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'ffmpeg' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "!ffmpeg -hide_banner -loglevel error -i \"./processed/movie_optical.avi\" -y \"./processed/movie_optical.mp4\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52f752d4e02d4e69b12f0af6692e3475",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Video(value=b'\\x00\\x00\\x00 ftypisom\\x00\\x00\\x02\\x00isomiso2avc1mp41\\x00\\x00\\r\\x1dmoov\\x00\\x00\\x00lmvhd\\x00\\x00…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Video.from_file('./processed/movie_optical.mp4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (quantum_mechanics)",
   "language": "python",
   "name": "quantum_mechanics"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
